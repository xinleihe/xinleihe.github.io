---
title: "Publications"
permalink: /publications/
author_profile: true
---

$^\dagger$: Corresponding author.

You can also find my publications on [Google Scholar](https://scholar.google.com/citations?user=6hZNEtoAAAAJ).


### <font size="3"><span style="color:rgb(0, 119, 181)">PEFTGuard: Detecting Backdoor Attacks Against Parameter-Efficient Fine-Tuning</span></font>  
<font size="3">Zhen Sun, Tianshuo Cong, Yule Liu, Chenhao Lin, <b>Xinlei He</b>$^\dagger$, Rongmao Chen, Xingshuo Han, and Xinyi Huang; <i>IEEE S&P 2025</i></font>


### <font size="3"><span style="color:rgb(0, 119, 181)">From Purity to Peril: Backdooring Merged Models From ‚ÄúHarmless‚Äù Benign Components</span></font>  
<font size="3">Lijin Wang, Jingjing Wang, Tianshuo Cong$^\dagger$, <b>Xinlei He</b>$^\dagger$, Zhan Qin, and Xinyi Huang; <i>USENIX Security 2025</i></font>


### <font size="3"><span style="color:rgb(0, 119, 181)">Safety Misalignment Against Large Language Models</span></font>
<font size="3">Yichen Gong, Delong Ran, <b>Xinlei He</b>, Tianshuo Cong, Anyu Wang, and Xiaoyun Wang <i>NDSS Symposium 2025</i></font>(AR: 211/1311=16.1%, AR Fall: 14.5%)
üéñÔ∏è Artifact Badges: Available, Functional, Reproduced

### <font size="3"><span style="color:rgb(0, 119, 181)">CL-Attack: Textual Backdoor Attacks via Cross-Lingual Triggers</span></font>  
<font size="3">Jingyi Zheng, Tianyi Hu, Tianshuo Cong, and <b>Xinlei He</b>$^\dagger$; <i>AAAI 2025</i></font>

### <font size="3"><span style="color:rgb(0, 119, 181)">Have You Merged My Model? On The Robustness of Large Language Model IP Protection Methods Against Model Merging</span></font>  
<font size="3">Tianshuo Cong, Delong Ran, Zesen Liu, <b>Xinlei He</b>, Jinyuan Liu, Yichen Gong, Qi Li, Anyu Wang, Xiaoyun Wang; <i>1st ACM CCS Workshop on Large AI Systems and Models with Privacy and Safety Analysis (LAMPS)</i></font>üèÜ Best Paper Award
<!-- [![img](https://img.shields.io/badge/paper-fac205)](https://arxiv.org/abs/2303.14822) 
[![img](https://img.shields.io/badge/code-fac205)](https://github.com/xinleihe/MGTBench) -->


### <font size="3"><span style="color:rgb(0, 119, 181)">MGTBench: Benchmarking Machine-Generated Text Detection</span></font>  
<font size="3"><b>Xinlei He</b>, Xinyue Shen, Zeyuan Chen, Michael Backes, Yang Zhang; <i>CCS 2024</i></font>
[![img](https://img.shields.io/badge/paper-fac205)](https://arxiv.org/abs/2303.14822) 
[![img](https://img.shields.io/badge/code-fac205)](https://github.com/xinleihe/MGTBench)

### <font size="3"><span style="color:rgb(0, 119, 181)">SecurityNet: Assessing Machine Learning Vulnerabilities on Public Models</span></font>  
<font size="3">Boyang Zhang, Zheng Li, Ziqing Yang,<b>Xinlei He</b>, Michael Backes, Mario Fritz, Yang Zhang; <i>USENIX Security 2024</i></font>
[![img](https://img.shields.io/badge/paper-fac205)](https://arxiv.org/abs/2310.12665) 
[![img](https://img.shields.io/badge/code-fac205)](https://github.com/SecurityNet-Research/SecurityNet)

### <font size="3"><span style="color:rgb(0, 119, 181)">You Only Prompt Once: On the Capabilities of Prompt Learning on Large Language Models to Tackle Toxic Content</span></font>  
<font size="3"><b>Xinlei He</b>, Savvas Zannettou, Yun Shen, Yang Zhang; <i>S&P 2024</i></font>
[![img](https://img.shields.io/badge/paper-fac205)](https://arxiv.org/abs/2308.05596)
[![img](https://img.shields.io/badge/code-fac205)](https://github.com/xinleihe/toxic-promp)

### <font size="3"><span style="color:rgb(0, 119, 181)">Test-Time Poisoning Attacks Against Test-Time Adaptation Models</span></font>  
<font size="3">Tianshuo Cong, <b>Xinlei He</b>, Yun Shen, Yang Zhang; <i>S&P 2024</i></font>
[![img](https://img.shields.io/badge/paper-fac205)](https://arxiv.org/abs/2308.08505)
[![img](https://img.shields.io/badge/code-fac205)](https://github.com/tianshuocong/TePA)

### <font size="3"><span style="color:rgb(0, 119, 181)">Link Stealing Attacks Against Inductive Graph Neural Networks</span></font>  
<font size="3">Yixin Wu, <b>Xinlei He</b>, Pascal Berrang, Mathias Humbert, Michael Backes, Neil Zhenqiang Gong, Yang Zhang; <i>PoPETS 2024</i></font>
<!-- [![img](https://img.shields.io/badge/paper-fac205)](https://arxiv.org/abs/2308.08505)
[![img](https://img.shields.io/badge/code-fac205)](https://github.com/tianshuocong/TePA) -->


### <font size="3"><span style="color:rgb(0, 119, 181)">Unsafe Diffusion: On the Generation of Unsafe Images and Hateful Memes From Text-To-Image Models</span></font>  
<font size="3">Yiting Qu, Xinyue Shen, <b>Xinlei He</b>, Michael Backes, Savvas Zannettou, Yang Zhang; <i>CCS 2023</i></font>
[![img](https://img.shields.io/badge/paper-fac205)](https://arxiv.org/abs/2305.13873) 
[![img](https://img.shields.io/badge/code-fac205)](https://github.com/YitingQu/unsafe-diffusion)

### <font size="3"><span style="color:rgb(0, 119, 181)">Data Poisoning Attacks Against Multimodal Encoders</span></font>  
<font size="3">Ziqing Yang, <b>Xinlei He</b>, Zheng Li, Michael Backes, Mathias Humbert, Pascal Berrang, Yang Zhang; <i>ICML 2023</i></font>
[![img](https://img.shields.io/badge/paper-fac205)](https://arxiv.org/abs/2209.15266) 
[![img](https://img.shields.io/badge/code-fac205)](https://github.com/zqypku/mm_poison/)

### <font size="3"><span style="color:rgb(0, 119, 181)">Generated Graph Detection</span></font>  
<font size="3">Yihan Ma, Zhikun Zhang, Ning Yu, <b>Xinlei He</b>, Michael Backes, Yun Shen, Yang Zhang; <i>ICML 2023</i></font>
[![img](https://img.shields.io/badge/paper-fac205)](https://arxiv.org/abs/2306.07758)
[![img](https://img.shields.io/badge/code-fac205)](https://github.com/Yvonnemamama/GGD)

### <font size="3"><span style="color:rgb(0, 119, 181)">Can't Steal? Cont-Steal! Contrastive Stealing Attacks Against Image Encoders</span></font>  
<font size="3">Zeyang Sha, <b>Xinlei He</b>, Ning Yu, Michael Backes, Yang Zhang; <i>CVPR 2023</i></font>
[![img](https://img.shields.io/badge/paper-fac205)](https://arxiv.org/pdf/2201.07513.pdf)
[![img](https://img.shields.io/badge/code-fac205)](https://github.com/zeyangsha/Cont-Steal) 

### <font size="3"><span style="color:rgb(0, 119, 181)">A Plot is Worth a Thousand Words: Model Information Stealing Attacks via Scientific Plots</span></font>  
<font size="3">Boyang Zhang, <b>Xinlei He</b>, Yun Shen, Tianhao Wang, Yang Zhang; <i>USENIX Security 2023</i></font>
[![img](https://img.shields.io/badge/paper-fac205)](https://arxiv.org/abs/2302.11982)
[![img](https://img.shields.io/badge/code-fac205)](https://github.com/boz083/Plot_Steal)

### <font size="3"><span style="color:rgb(0, 119, 181)">On the Evolution of (Hateful) Memes by Means of Multimodal Contrastive Learning</span></font>  
<font size="3">Yiting Qu, <b>Xinlei He</b>, Shannon Pierson, Michael Backes, Yang Zhang, Savvas Zannettou; <i>S&P 2023</i></font>
[![img](https://img.shields.io/badge/paper-fac205)](https://arxiv.org/abs/2212.06573)
[![img](https://img.shields.io/badge/code-fac205)](https://github.com/YitingQu/meme-evolution)


### <font size="3"><span style="color:rgb(0, 119, 181)">Semi-Leak: Membership Inference Attacks Against Semi-supervised Learning</span></font>  
<font size="3"><b>Xinlei He</b>, Hongbin Liu, Neil Zhenqiang Gong, Yang Zhang; <i>ECCV 2022</i></font>
[![img](https://img.shields.io/badge/paper-fac205)]()
[![img](https://img.shields.io/badge/code-fac205)]()


### <font size="3"><span style="color:rgb(0, 119, 181)">SSLGuard: A Watermarking Scheme for Self-supervised Learning Pre-trained Encoders</span></font>  
<font size="3">Tianshuo Cong, <b>Xinlei He</b>, Yang Zhang; <i>CCS 2022</i></font>
[![img](https://img.shields.io/badge/paper-fac205)](https://arxiv.org/abs/2201.11692)
[![img](https://img.shields.io/badge/code-fac205)]()

<!-- <a href="" class="btn btn-primary">code</a> -->
<!-- [pdf](){: .btn--danger}{:target="_blank"} [arxiv](https://arxiv.org/abs/2201.11692){: .btn--danger}{:target="_blank"} ![img](https://img.shields.io/badge/code-fac205)(){: .btn--danger}{:target="_blank"} -->


### <font size="3"><span style="color:rgb(0, 119, 181)">Auditing Membership Leakages of Multi-Exit Networks</span></font>  
<font size="3">Zheng Li, Yiyong Liu, <b>Xinlei He</b>, Ning Yu, Michael Backes, Yang Zhang; <i>CCS 2022</i></font>  
[![img](https://img.shields.io/badge/paper-fac205)]()
[![img](https://img.shields.io/badge/code-fac205)]()


### <font size="3"><font size="3"><span style="color:rgb(0, 119, 181)">Model Stealing Attacks Against Inductive Graph Neural Networks</span></font>  
<font size="3">Yun Shen*, <b>Xinlei He*</b>, Yufei Han, Yang Zhang (* Equal Contribution); <i>S&P 2022</i></font>  
[![img](https://img.shields.io/badge/paper-fac205)](https://arxiv.org/abs/2112.08331)
[![img](https://img.shields.io/badge/code-fac205)](https://github.com/xinleihe/GNNStealing)




### <font size="3"><span style="color:rgb(0, 119, 181)">ML-Doctor: Holistic Risk Assessment of Inference Attacks Against Machine Learning Models</span></font>  
<font size="3">Yugeng Liu, Rui Wen, <b>Xinlei He</b>, Ahmed Salem, Zhikun Zhang, Michael Backes, Emiliano De Cristofaro, Mario Fritz, Yang Zhang; <i>USENIX Security 2022</i></font>  
[![img](https://img.shields.io/badge/paper-fac205)](http://yangzhangalmo.github.io/papers/USENIXSECURITY22-MLDoctor.pdf)
[![img](https://img.shields.io/badge/code-fac205)](https://github.com/liuyugeng/ML-Doctor)


### <font size="3"><font size="3"><span style="color:rgb(0, 119, 181)">On Xing Tian and the Perseverance of Anti-China Sentiment Online</span></font>  
<font size="3">Xinyue Shen, <b>Xinlei He</b>, Michael Backes, Jeremy Blackburn, Savvas Zannettou, Yang Zhang; <i>ICWSM 2022</i></font>  
[![img](https://img.shields.io/badge/paper-fac205)](http://yangzhangalmo.github.io/papers/ICWSM22.pdf)


### <font size="3"><span style="color:rgb(0, 119, 181)">Quantifying and Mitigating Privacy Risks of Contrastive Learning</span></font>  
<font size="3"><b>Xinlei He</b>, Yang Zhang; <i>CCS 2021</i></font> 
[![img](https://img.shields.io/badge/paper-fac205)](http://yangzhangalmo.github.io/papers/CCS21-ContrastivePrivacy.pdf)
[![img](https://img.shields.io/badge/code-fac205)](https://github.com/xinleihe/ContrastiveLeaks)


### <font size="3"><span style="color:rgb(0, 119, 181)">Stealing Links from Graph Neural Networks</span></font>  
<font size="3"><b>Xinlei He</b>, Jinyuan Jia, Michael Backes, Neil Zhenqiang Gong, Yang Zhang; <i>USENIX Security 2021</i></font> 
[![img](https://img.shields.io/badge/paper-fac205)](https://arxiv.org/abs/2005.02131)
[![img](https://img.shields.io/badge/code-fac205)](https://github.com/xinleihe/link_stealing_attack)



### <font size="3"><span style="color:rgb(0, 119, 181)">Trimming Mobile Applications for Bandwidth-Challenged Networks in Developing Regions</span></font>  
<font size="3">Qinge Xie, Qingyuan Gong, <b>Xinlei He</b>, Yang Chen, Xin Wang, Haitao Zheng, Ben Y. Zhao; <i>IEEE Transactions on Mobile Computing (TMC)</i></font>
[![img](https://img.shields.io/badge/paper-fac205)](https://arxiv.org/abs/1912.01328)


### <font size="3"><span style="color:rgb(0, 119, 181)">DatingSec: Detecting Malicious Accounts in Dating Apps Using a Content-Based Attention Network</span></font>  
<font size="3"><b>Xinlei He</b>, Qingyuan Gong, Yang Chen, Yang Zhang, Xin Wang, Xiaoming Fu; <i>IEEE Transactions on Dependable and Secure Computing (TDSC)</i></font>
[![img](https://img.shields.io/badge/paper-fac205)](https://ieeexplore.ieee.org/document/9384217)


### Prior to PhD:

### <font size="3"><span style="color:rgb(0, 119, 181)">Cross-Site Prediction on Social Influence for Cold-Start Users in Online Social Networks</span></font>  
<font size="3">Qingyuan Gong, Yang Chen, <b>Xinlei He</b>, Yu Xiao, Pan Hui, Xin Wang, Xiaoming Fu; <i>ACM Transactions on the Web (TWEB)</i></font>
[![img](https://img.shields.io/badge/paper-fac205)](https://dl.acm.org/doi/10.1145/3409108)

### <font size="3"><span style="color:rgb(0, 119, 181)">DeepScan: Exploiting Deep Learning for Malicious Account Detection in Location-Based Social Networks</span></font>  
<font size="3">Qingyuan Gong, Yang Chen, <b>Xinlei He</b>, Zhou Zhuang, Tianyi Wang, Hong Huang, Xin Wang, Xiaoming Fu; <i>IEEE Communications Magazine</i></font>  
[![img](https://img.shields.io/badge/paper-fac205)](/files/DeepScan-COMMAG18.pdf)

